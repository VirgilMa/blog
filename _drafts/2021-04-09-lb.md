---
layout: post
title: "Load Balancer"
---

[toc]

## Duet

## SilkRoad: Making Stateful Layer-4 Load Balancing Fast and Cheap Using Switching ASICs

### Introduction

**Function of Load balancer**: map packets destined to a service (with a virtual IP address, or **VIP**), to a pool of servers tasked with providing the service (with multiple direct IP addresses, or **DIPs**).

Two major challenges of LB:

- **support full bisection traffic with low latency**: 

- **per-connection consistency (PCC)**: it must always map a connection to the same server (DIP), even if the pool of servers changes and/or if the load is spread differently across the pool.

Challenge of switch ASICs: cannot maintain per-connection states. memory limitation

### Background on LB

#### Layer 4 LB

- VIPTable
- ConnTable
- PCC challenge

#### Limitation of software LB

- high cost of server resources
- high latency and jitter (50Î¼s -> 1ms)
- poor performance isolation

#### Duet: storing VIPTable in ASICs

- only use switch to handle VIPs with high-volume traffic and employs a few SLBs to handle other VIPs
- cannot handle frequent DIP pool updates

### Challenges of frequent dip pool updates

#### Frequent DIP Pool updates

- why: main reason is upgrading of web services;
- why cannot reduce:
  - delaying the execution of some updates: hurt application performance and reliability, especially for updates that swap out a faulty DIP;
  - merge multiple DIP updates of the same VIP into a batch: different waking up time => have to handle DIP additions separately.

#### Problems of storing ConnTable in SLBs

when updating, the connection has to be handled by SLB. BUT, when to migrate VIP from SLBs back to switches?

- migrate-1 min: severe PCC violate
- migrate-10 min: performance degrade and PCC violate
- migrate-PCC: performance degrade

### SILKROAD Design

implement both ConnTable and VIPTable on switching ASICs.

- to store mill conns: hash digest & eliminate false positive & DIP pool version
- to ensure PCC: handle slow ConnTable insertion => bloom filter remember the newly arrived connections during DIP pool updates

#### Features in commodity switching ASICs

- increase SRAM size: 50-100 MB
- connection learning and insertion:
  - Modern switching ASIC often take an approach known as cuckoo hashing to implement rule table.
    - when hash collision happened, it needs to run a complex search algorithm (BFS) to find an empty slot.
  - learning filter (available in ASICs for L2 MAC learning) to push a new connection event to CPU.
- Transactional memory 
  - read-check-modify-write is done in one clock cycle time.

#### Scaling to millions of connections

##### compact connection match keys by hash digests: 37bytes => 16bits (2bytes)

- false positive: if a packet with TCP SYN toggled matches an existing entry, it will be redirected to CPU.

#### Ensuring PCC

### Implementation and deployment

#### prototype implementation

#### prototype performance and overhead

#### network-wide deployment

### Evaluation

#### Scalability

#### Ensuring PCC

### Discussion

### Related work

### Conclusion



